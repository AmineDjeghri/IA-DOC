{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  OpenClassroom & Towards Science "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EPuDBYkZDQF_"
   },
   "source": [
    "1- Faire d'abord le tp d'openclassroom et s'arreter à la partie \n",
    "' Utilisation du VGG-16 pré-entraîné' \n",
    "\n",
    "2- Faire le tuto de towards data science \n",
    "\n",
    "3- continuer le tuto d'open classroom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HELuxKy0DQF8"
   },
   "source": [
    "## Parties 1 & 3 - OpenClassroom TP- Implémentez votre premier réseau de neurones avec Keras\n",
    "\n",
    "OpenClassroom: https://openclassrooms.com/fr/courses/4470531-classez-et-segmentez-des-donnees-visuelles/5097666-tp-implementez-votre-premier-reseau-de-neurones-avec-keras\n",
    "\n",
    "## Partie 2 - Building a Convolutional Neural Network (CNN) in Keras\n",
    "\n",
    "TowardsDataScience: https://towardsdatascience.com/building-a-convolutional-neural-network-cnn-in-keras-329fbbadc5f5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QCEGYrN8DQGA"
   },
   "source": [
    "## 1- Solution de l'implémentation de VGG-16 (openclassroom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jEsTyejrDQGB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Fatah\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "\n",
    "my_VGG16= Sequential()\n",
    "\n",
    "#1st bloc\n",
    "my_VGG16.add(Conv2D(64,(3,3),input_shape=(224,224,3),padding='same',activation='relu'))\n",
    "\n",
    "my_VGG16.add(Conv2D(64,(3,3),padding='same',activation='relu'))\n",
    "\n",
    "my_VGG16.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O5JABS3iDQGJ"
   },
   "outputs": [],
   "source": [
    "#2nd Bloc\n",
    "my_VGG16.add(Conv2D(128,(3,3),padding='same',activation='relu'))\n",
    "\n",
    "my_VGG16.add(Conv2D(128,(3,3),padding='same',activation='relu'))\n",
    "\n",
    "my_VGG16.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "#3rd bloc\n",
    "my_VGG16.add(Conv2D(256,(3,3),padding='same',activation='relu'))\n",
    "\n",
    "my_VGG16.add(Conv2D(256,(3,3),padding='same',activation='relu'))\n",
    "\n",
    "my_VGG16.add(Conv2D(256,(3,3),padding='same',activation='relu'))\n",
    "\n",
    "my_VGG16.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "\n",
    "#4th bloc\n",
    "my_VGG16.add(Conv2D(512,(3,3),padding='same',activation='relu'))\n",
    "\n",
    "my_VGG16.add(Conv2D(512,(3,3),padding='same',activation='relu'))\n",
    "\n",
    "my_VGG16.add(Conv2D(512,(3,3),padding='same',activation='relu'))\n",
    "\n",
    "my_VGG16.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "#5th bloc\n",
    "my_VGG16.add(Conv2D(512,(3,3),padding='same',activation='relu'))\n",
    "\n",
    "my_VGG16.add(Conv2D(512,(3,3),padding='same',activation='relu'))\n",
    "\n",
    "my_VGG16.add(Conv2D(512,(3,3),padding='same',activation='relu'))\n",
    "\n",
    "my_VGG16.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IQwTWWZvDQGN"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Flatten, Dense\n",
    "\n",
    "# Conversion des matrices 3D en vecteur 1D\n",
    "my_VGG16.add(Flatten())\n",
    "\n",
    "my_VGG16.add(Dense(4096, activation='relu'))\n",
    "\n",
    "my_VGG16.add(Dense(4096,activation='relu'))\n",
    "my_VGG16.add(Dense(1000,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HpPjozxqDQGR"
   },
   "source": [
    "On va load notre dataset, lui faire les prétraitements necessaires, puis creer notre model vgg, le compiler et enfin l'entrainer et le tester.\n",
    "\n",
    "Mais avant faire le tuto de Towards DataScience "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "29aJdzipDQGS"
   },
   "source": [
    "## 2- Towards Data Science "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pNPqfkL5DQGT"
   },
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tiqcxVDsDQGV",
    "outputId": "dcc33294-d108-496c-ae7b-b133f9d05e3b"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "#download mnist data and split into train and test sets\n",
    "(X_train, y_train), (X_test,y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tQrn1LQxDQGf",
    "outputId": "8d2d89c9-bea1-425b-80ee-67bc1c084c1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c11bb82c88>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#let’s take a look at one of the images in our dataset\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "#plot the first image in the dataset \n",
    "plt.imshow(X_train[0],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bUS8ILQsDQGm",
    "outputId": "eb49a601-d5ee-4392-dae6-b5ee10278d8c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check image shape\n",
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jkb_vdqTDQGr",
    "outputId": "19bec0a2-1ae3-4f52-c6ed-140f9edb5c65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check xtrain exemples\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VcqoO5gWDQGx"
   },
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qz8XrCVaDQGy"
   },
   "source": [
    "Next, we need to reshape our dataset inputs (X_train and X_test) to the shape that our model expects when we train the model. The first number is the number of images (60,000 for X_train and 10,000 for X_test). Then comes the shape of each image (28x28). The last number is 1, which signifies that the images are greyscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "55l0LEEADQG0"
   },
   "outputs": [],
   "source": [
    "#reshape data to fit model\n",
    "\n",
    "X_train=X_train.reshape(60000,28,28,1)\n",
    "X_test=X_test.reshape(10000,28,28,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HU2l3qD7DQG6"
   },
   "source": [
    "We need to ‘one-hot-encode’ our target variable. \n",
    "\n",
    "There are 10 classes ( 0 to 9) so our target will have 10 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kSiUv438DQG8",
    "outputId": "7e27bc65-7119-4c74-fc70-942c5f0901da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "#one-hot encode target column\n",
    "y_train=to_categorical(y_train)\n",
    "y_test=to_categorical(y_test)\n",
    "\n",
    "#see an exemple\n",
    "y_train[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9xH24HawDQHB",
    "outputId": "3979f4ef-0607-4aac-becf-0ceb3c1b4210"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HDFbILS3DQHH"
   },
   "source": [
    "### Building a small model to test before applying VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UG_X_qKPDQHK"
   },
   "source": [
    "this model takes the same input as the images of the daset 28x28 not like VGG-16\n",
    "( i need to see if it is normal to reshape to 128x 128 for vgg-16 or i can do another thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AuFbv6dSDQHO",
    "outputId": "0d8aa445-b734-43f2-a3f3-327ecf8a8d8a"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "from keras.layers import Flatten, Dense\n",
    "\n",
    "#create model\n",
    "model = Sequential()\n",
    "#add model layers\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "efGaf2OgDQHT"
   },
   "source": [
    "### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "objP6MzIDQHV"
   },
   "outputs": [],
   "source": [
    "#compile model \n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XghJ8WNDDQHa"
   },
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_aBELQ73DQHb"
   },
   "source": [
    "Lien pour mieux comprendre les termes epochs ...ect\n",
    "https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0u3PVLtnDQHc",
    "outputId": "8f201602-a021-4f2a-acb9-b277661504af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Fatah\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 167s 3ms/step - loss: 2.1646 - acc: 0.8383 - val_loss: 0.0847 - val_acc: 0.9741\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 162s 3ms/step - loss: 0.0702 - acc: 0.9792 - val_loss: 0.0914 - val_acc: 0.9737\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 164s 3ms/step - loss: 0.0422 - acc: 0.9869 - val_loss: 0.0885 - val_acc: 0.9767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x143ccfeb470>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model\n",
    "model.fit(X_train, y_train, epochs=3, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u4-g0kOBDQHr"
   },
   "source": [
    "### make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ptgqWDunDQHs"
   },
   "source": [
    "The predict function will give an array with 10 numbers. These numbers are the probabilities that the input image represents each digit (0–9).\n",
    "\n",
    "To show this, we will show the predictions for the first 4 images in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2vznx8BlDQHu",
    "outputId": "f8998280-64ad-4c8d-b5ee-89af7f0b8712"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.8612938e-06, 3.0342020e-12, 2.9125427e-08, 2.2747287e-08,\n",
       "        2.2083599e-10, 7.0136332e-09, 3.5075218e-14, 9.9999595e-01,\n",
       "        1.0779497e-09, 1.1467720e-06],\n",
       "       [5.8986753e-09, 8.2773511e-08, 9.9999976e-01, 3.1506091e-12,\n",
       "        3.5673355e-13, 1.9024819e-12, 6.3658746e-08, 1.0743872e-15,\n",
       "        4.3923696e-09, 8.7973472e-14],\n",
       "       [1.8281975e-07, 9.9960583e-01, 2.2667465e-04, 1.5185622e-10,\n",
       "        1.3266495e-05, 4.5351271e-07, 8.2485991e-07, 4.6749037e-07,\n",
       "        1.5233376e-04, 2.4984505e-08],\n",
       "       [9.9999976e-01, 3.3063157e-12, 3.6905856e-09, 2.7756084e-15,\n",
       "        3.5918926e-10, 5.1442974e-09, 2.3101263e-07, 3.8744580e-12,\n",
       "        1.5961875e-09, 1.7021989e-08]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict first 4 images in the test set\n",
    "model.predict(X_test[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QrcsuLfIDQH4"
   },
   "source": [
    "### compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gbonGjkFDQH5",
    "outputId": "13d03cfc-4d0d-4947-a3aa-4734c139ca9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#actual results for first 4 images in test set are the same as we predicted\n",
    "y_test[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s1j-YesKDQH_"
   },
   "source": [
    "## Utilisation du VGG-16 pré-entraîné ( suite de Openclassroom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g-toBvkCDQIA"
   },
   "source": [
    "Dans cette partie, nous allons apprendre à classifier des images avec le modèle VGG-16 fourni par Keras et pré-entraîné sur ImageNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IEosCAXLDQIB"
   },
   "source": [
    "### Charger le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a3KxfaLbDQIC"
   },
   "source": [
    "Charger ce modèle avec la classe VGG16 de  keras.applications.vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O3RhE9LXDQID",
    "outputId": "0d4b6ad0-751c-4a29-f35a-fec807b46a8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467904/553467096 [==============================] - 1526s 3us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "vgg16=VGG16()\n",
    "#print(vgg16.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b_fzAYkgDQII"
   },
   "source": [
    "Par défaut, le constructeur  VGG16()  crée le réseau VGG-16 pré-entraîné sur ImageNet. Si à l'avenir, pour d'autres projets, vous souhaitez initialiser aléatoirement les poids, il faudra préciser  weight=None  en argument.\n",
    "\n",
    "Le constructeur possède d'autres paramètres pour faire du Transfer Learning, que nous allons utiliser dans la partie suivante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nc6uBMAjDQIK"
   },
   "source": [
    "### Prétraitemens et training\n",
    "\n",
    "(voir explications sur le site d'OCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ZClvXlHDQIL"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "#charger l'image\n",
    "img=load_img('C:\\\\Users\\Fatah\\Downloads\\Stage\\Pratique\\chat.jpg',target_size=(224,224)) \n",
    "\n",
    "# Convertir en tableau numpy\n",
    "img= img_to_array(img)\n",
    "\n",
    "# Créer la collection d'images (un seul échantillon)\n",
    "img=img.reshape((1,img.shape[0],img.shape[1],img.shape[2]))\n",
    "\n",
    "# Prétraiter l'image comme le veut VGG-16\n",
    "img=preprocess_input(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ZCs5XdSDQIO"
   },
   "source": [
    "### Prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rt8Q_7YMDQIP",
    "outputId": "5a20c424-fbc3-41f8-b7c1-29205ffd1410"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.18879237e-07, 3.19112723e-06, 1.03933389e-05, 4.45714886e-06,\n",
       "        8.32834485e-06, 7.70751114e-07, 7.31312895e-08, 1.53171477e-05,\n",
       "        8.27017175e-06, 2.22088347e-05, 1.37284940e-06, 7.81323138e-07,\n",
       "        1.73867954e-06, 1.09971745e-06, 5.58299121e-07, 1.55368946e-06,\n",
       "        1.03659636e-06, 4.63099677e-05, 1.89865227e-06, 1.49072707e-06,\n",
       "        1.61153139e-06, 1.31601564e-05, 9.85401584e-07, 4.97673045e-06,\n",
       "        4.03967215e-06, 9.85214569e-07, 2.77224035e-06, 1.36000710e-06,\n",
       "        4.64407231e-06, 1.86058278e-05, 3.03549484e-07, 7.43710132e-07,\n",
       "        6.34962248e-07, 6.29382612e-07, 7.88674640e-07, 2.29430952e-07,\n",
       "        6.30541172e-06, 7.91516811e-07, 7.95826636e-05, 1.17343075e-06,\n",
       "        3.36580592e-06, 8.31603575e-06, 1.66191467e-06, 4.85602527e-07,\n",
       "        4.93676052e-05, 5.32562308e-06, 1.07956812e-05, 9.95438995e-07,\n",
       "        4.83699182e-07, 3.32998781e-07, 1.19684739e-06, 3.16932096e-06,\n",
       "        6.27417239e-06, 8.76926720e-07, 7.22341520e-06, 6.33414572e-07,\n",
       "        3.41035297e-06, 4.13697904e-07, 4.90695470e-07, 5.73131229e-06,\n",
       "        1.24323433e-05, 7.40517578e-07, 1.66466850e-06, 1.50121232e-05,\n",
       "        2.12395548e-06, 4.49004858e-07, 1.35163818e-05, 2.88745980e-07,\n",
       "        3.15509578e-06, 3.51387399e-08, 7.56379904e-07, 8.73740828e-06,\n",
       "        2.59348985e-06, 1.86629165e-06, 9.75885769e-07, 4.87022191e-07,\n",
       "        1.40170448e-06, 1.36550841e-06, 3.33814023e-05, 1.48445297e-05,\n",
       "        8.80067182e-06, 9.33809952e-06, 8.59903503e-06, 3.66377644e-05,\n",
       "        7.14198759e-05, 2.74786385e-06, 6.76871423e-06, 1.03044158e-05,\n",
       "        7.21366348e-07, 4.80566143e-07, 1.01603700e-06, 3.64867105e-07,\n",
       "        8.33497111e-08, 7.24829533e-07, 1.76195754e-05, 1.30852669e-07,\n",
       "        7.20536491e-07, 1.71951842e-06, 2.61416267e-06, 1.10978899e-05,\n",
       "        8.28839120e-07, 2.64593840e-08, 4.03704962e-06, 8.36790832e-07,\n",
       "        8.78166175e-05, 1.93350729e-06, 1.17201325e-05, 2.13848170e-06,\n",
       "        6.04916409e-07, 2.88458097e-07, 2.37811423e-06, 1.88496426e-06,\n",
       "        1.53519813e-05, 2.35664356e-06, 7.22440018e-06, 1.89522416e-06,\n",
       "        1.16843076e-07, 3.14601607e-06, 2.49679556e-06, 1.39849519e-07,\n",
       "        4.17012160e-07, 1.14927150e-06, 2.24879136e-06, 5.73744046e-07,\n",
       "        8.44006081e-06, 5.85570024e-06, 4.79765959e-06, 4.28770051e-07,\n",
       "        1.91972262e-07, 4.07897062e-07, 1.84102680e-06, 1.19174592e-06,\n",
       "        4.81803590e-06, 8.35303922e-07, 3.57911813e-06, 1.61809396e-07,\n",
       "        5.50779021e-07, 1.56248154e-06, 7.32322178e-06, 1.75860919e-06,\n",
       "        1.11280053e-06, 7.14001942e-07, 1.11384885e-07, 6.32103877e-07,\n",
       "        7.17660328e-07, 1.38374082e-06, 7.75411809e-06, 3.87059572e-06,\n",
       "        9.08930542e-06, 7.11856160e-07, 2.68449512e-05, 1.36285194e-03,\n",
       "        2.92334444e-05, 1.17050195e-05, 1.14700342e-05, 9.32155945e-06,\n",
       "        3.30971889e-05, 1.95729750e-04, 1.43285419e-04, 3.88177966e-07,\n",
       "        1.05775989e-05, 1.79391213e-06, 4.17972296e-06, 1.92930224e-06,\n",
       "        4.45059914e-06, 3.04400601e-07, 1.81850965e-06, 2.54546990e-06,\n",
       "        2.55441410e-06, 3.51002091e-05, 6.39663222e-06, 6.38976417e-05,\n",
       "        2.84493144e-05, 2.20948525e-04, 4.91466344e-05, 2.52530936e-06,\n",
       "        6.99927205e-06, 8.68632924e-06, 1.06022617e-05, 5.88901344e-07,\n",
       "        1.52779114e-06, 2.84486377e-05, 3.68243150e-06, 2.39352926e-06,\n",
       "        2.45972547e-06, 3.70405905e-05, 5.35766849e-05, 3.04763904e-04,\n",
       "        5.51449702e-05, 6.01160173e-06, 5.09537676e-06, 3.41574628e-06,\n",
       "        7.65664936e-06, 2.88384945e-05, 4.77853609e-06, 9.79775432e-05,\n",
       "        2.02113097e-05, 3.31474916e-06, 7.73596184e-06, 4.85577766e-06,\n",
       "        1.49138828e-06, 5.81414097e-05, 3.52898655e-06, 1.09476699e-04,\n",
       "        4.01627040e-06, 1.43812463e-06, 4.66944584e-07, 4.90200364e-06,\n",
       "        4.35020502e-06, 4.93132518e-07, 2.42978945e-06, 2.00903082e-06,\n",
       "        3.87895234e-05, 4.02186652e-06, 1.35457969e-06, 3.29858631e-05,\n",
       "        7.50041181e-06, 1.85900080e-05, 2.35935222e-05, 4.03551712e-06,\n",
       "        6.16429759e-07, 5.75499769e-07, 1.26483847e-05, 1.00119478e-05,\n",
       "        2.69906718e-06, 1.58132775e-06, 3.51820313e-06, 1.23103155e-05,\n",
       "        1.51182167e-06, 1.33008789e-05, 4.70512487e-06, 7.90197373e-06,\n",
       "        4.74614244e-05, 2.96756980e-06, 1.18481285e-06, 1.00562684e-04,\n",
       "        3.54866552e-06, 2.63286875e-05, 1.77437926e-06, 2.76488163e-06,\n",
       "        1.33372771e-06, 1.25304666e-06, 1.67219616e-06, 5.97188546e-07,\n",
       "        1.49628613e-06, 3.03238758e-05, 1.94735603e-05, 5.17513354e-06,\n",
       "        3.59869096e-03, 4.63771255e-04, 1.83022243e-03, 6.38099504e-04,\n",
       "        2.21830828e-06, 1.30434928e-05, 2.80881068e-06, 3.70406582e-07,\n",
       "        1.14464467e-06, 1.91020808e-05, 2.45431875e-05, 2.57624051e-05,\n",
       "        8.52647588e-07, 7.39809957e-06, 2.79010123e-06, 2.36630385e-05,\n",
       "        2.86178929e-05, 3.13519886e-05, 4.17257843e-06, 3.14453405e-06,\n",
       "        1.62589873e-04, 4.05064966e-05, 8.89060175e-05, 1.54875506e-05,\n",
       "        3.07339506e-05, 7.88105081e-06, 1.72115997e-05, 6.66930009e-06,\n",
       "        1.70328785e-05, 2.45742325e-04, 8.76493345e-04, 1.29006582e-03,\n",
       "        3.80704616e-04, 2.46138014e-02, 1.42266061e-02, 1.53620073e-04,\n",
       "        4.86081466e-03, 8.18569124e-01, 1.87856749e-05, 5.86405862e-03,\n",
       "        2.04924854e-05, 3.88113578e-04, 6.96550433e-06, 1.64543053e-07,\n",
       "        1.12222056e-04, 3.07263326e-05, 4.02956573e-07, 9.16302668e-07,\n",
       "        9.51654874e-06, 2.12609265e-07, 2.06042623e-05, 1.97491900e-04,\n",
       "        7.57640407e-07, 7.27655333e-07, 4.75910042e-07, 2.96592987e-07,\n",
       "        3.32199299e-08, 7.50245093e-08, 1.22840277e-06, 1.79160651e-07,\n",
       "        1.97648274e-06, 2.23587290e-06, 1.96029009e-06, 2.19530557e-06,\n",
       "        7.45785485e-07, 9.43075520e-06, 4.08409551e-06, 2.33092451e-05,\n",
       "        1.17659636e-06, 1.67323535e-07, 4.65055200e-06, 2.21899609e-06,\n",
       "        3.68458615e-07, 6.73510499e-07, 1.30494016e-07, 2.19542997e-07,\n",
       "        1.54385543e-06, 1.59055915e-07, 3.76907650e-07, 1.39107560e-05,\n",
       "        8.44102999e-07, 8.53507515e-07, 1.26813160e-04, 3.37924401e-04,\n",
       "        2.14856002e-04, 1.94388907e-04, 1.56975602e-05, 9.21422106e-05,\n",
       "        1.47115793e-06, 4.63020433e-06, 4.79815799e-06, 4.03083419e-07,\n",
       "        1.41303783e-04, 1.92438965e-05, 8.83235771e-07, 2.75372031e-07,\n",
       "        2.19854678e-06, 1.07571616e-07, 2.51721790e-08, 1.51053179e-08,\n",
       "        3.89646345e-07, 3.77853439e-07, 9.69628559e-07, 4.83097097e-07,\n",
       "        8.53371603e-07, 8.77991624e-06, 2.68195379e-07, 7.56543013e-05,\n",
       "        5.10018095e-02, 4.29180404e-03, 7.73176691e-03, 1.85039323e-02,\n",
       "        1.05986828e-05, 3.66901106e-04, 1.91405663e-04, 2.19969515e-05,\n",
       "        7.03586920e-07, 4.79893799e-07, 1.88000286e-07, 3.56951250e-06,\n",
       "        1.91062418e-06, 4.55966529e-07, 9.51459299e-07, 1.65929055e-06,\n",
       "        2.84218146e-07, 2.97446331e-06, 7.50435106e-07, 5.72380429e-07,\n",
       "        1.92132518e-07, 9.42438146e-06, 2.85267856e-06, 2.14444213e-07,\n",
       "        7.80598839e-06, 5.02458420e-07, 5.02778403e-06, 3.47577938e-04,\n",
       "        1.63767818e-05, 1.10783276e-07, 5.68379370e-08, 3.69407244e-05,\n",
       "        2.30098294e-06, 3.55153657e-06, 3.06420975e-06, 1.36436884e-05,\n",
       "        2.94030173e-07, 7.75388784e-08, 5.59159980e-06, 3.82903499e-06,\n",
       "        2.07802856e-07, 1.62536071e-06, 1.44800524e-05, 7.07777326e-06,\n",
       "        4.26692304e-06, 4.22471112e-06, 7.96825680e-06, 1.74232457e-06,\n",
       "        4.20926426e-06, 1.33487611e-05, 1.04674855e-05, 6.56131022e-07,\n",
       "        1.38617634e-06, 4.01828584e-06, 3.84821931e-07, 9.53168183e-06,\n",
       "        3.07536538e-04, 1.66134100e-06, 6.58114459e-07, 4.00661474e-06,\n",
       "        5.28403325e-04, 9.61665046e-06, 1.01092221e-04, 7.97223620e-05,\n",
       "        7.99340432e-06, 5.10367363e-06, 9.81030644e-06, 6.29961733e-06,\n",
       "        1.56555343e-05, 1.96680190e-07, 3.38414566e-06, 6.30110208e-06,\n",
       "        3.80769939e-06, 3.82074577e-05, 4.54533365e-05, 3.89526722e-05,\n",
       "        5.57420526e-06, 3.42670755e-05, 2.07309684e-04, 3.53439915e-04,\n",
       "        7.86560179e-07, 7.20619653e-07, 1.56168768e-04, 6.36085042e-06,\n",
       "        2.61709247e-05, 4.75485431e-05, 9.41133464e-07, 4.97616566e-06,\n",
       "        4.19763268e-07, 1.36388226e-05, 1.00175639e-05, 7.65458299e-06,\n",
       "        2.64965297e-06, 1.04487846e-07, 1.38283785e-05, 1.62139429e-06,\n",
       "        2.69507382e-05, 1.05159081e-04, 3.31142037e-05, 2.19083104e-05,\n",
       "        1.63103996e-05, 1.54744790e-04, 1.86006741e-06, 1.10172195e-05,\n",
       "        9.48124182e-07, 3.03320166e-06, 5.63292706e-05, 2.09383259e-04,\n",
       "        1.43763045e-05, 3.20222716e-06, 3.84240866e-06, 4.87673105e-06,\n",
       "        6.95413473e-06, 3.25576457e-06, 6.52352537e-05, 4.77461128e-07,\n",
       "        1.54648063e-07, 1.49707612e-05, 9.21642595e-07, 1.32188607e-05,\n",
       "        5.54644021e-06, 5.85324369e-06, 1.53396832e-04, 6.39596146e-06,\n",
       "        8.41167912e-06, 9.07195135e-06, 1.31195873e-06, 2.81995057e-07,\n",
       "        3.47395644e-06, 3.84434406e-06, 2.16683452e-06, 1.66278442e-05,\n",
       "        2.90931143e-06, 2.93806079e-06, 1.81191058e-06, 7.33332342e-07,\n",
       "        5.40910787e-06, 4.14407259e-06, 3.45647823e-06, 8.79733216e-06,\n",
       "        2.56550033e-04, 5.23194615e-07, 5.44772820e-06, 1.30278167e-05,\n",
       "        5.64765728e-08, 2.85710430e-05, 2.28560384e-06, 4.87176912e-05,\n",
       "        3.96331976e-04, 3.57522231e-06, 5.07182494e-06, 1.24150733e-06,\n",
       "        2.10155456e-04, 6.02605780e-07, 9.18820751e-06, 2.88238368e-07,\n",
       "        6.74846251e-06, 3.36863195e-06, 1.24461818e-04, 1.68157312e-05,\n",
       "        1.08898363e-04, 1.58829994e-06, 6.98929307e-06, 1.87407422e-05,\n",
       "        2.35261177e-05, 1.11446425e-05, 6.79487243e-07, 5.41052668e-06,\n",
       "        2.87041274e-07, 4.40025616e-07, 9.13908952e-05, 5.97287690e-05,\n",
       "        1.92453717e-06, 8.10270467e-06, 1.75026857e-04, 5.47015043e-06,\n",
       "        2.18169662e-05, 3.94645440e-06, 1.74727512e-03, 9.33218416e-07,\n",
       "        3.34407196e-06, 4.50242169e-06, 4.86315344e-07, 2.71847530e-04,\n",
       "        1.09322582e-06, 3.96224823e-06, 7.49977189e-05, 4.83475524e-05,\n",
       "        1.20625572e-07, 1.36685767e-05, 1.71750507e-05, 1.45638808e-07,\n",
       "        1.19676180e-04, 5.74033811e-06, 2.13837984e-06, 1.65150925e-06,\n",
       "        6.73457835e-05, 2.14748343e-05, 6.11919822e-05, 9.97324378e-07,\n",
       "        3.22928063e-05, 1.89260791e-05, 4.33025843e-06, 2.22563381e-06,\n",
       "        2.17453853e-05, 9.13452368e-07, 1.47215309e-04, 1.02938766e-05,\n",
       "        5.29342424e-06, 2.99519183e-06, 1.46739160e-06, 1.31278275e-05,\n",
       "        1.28492407e-04, 6.66747781e-07, 2.29287593e-06, 8.99462066e-07,\n",
       "        1.06566222e-04, 8.26873929e-07, 6.55631584e-06, 9.01166786e-08,\n",
       "        1.26958241e-06, 7.59894533e-07, 1.89284619e-05, 1.19137721e-05,\n",
       "        3.83464624e-07, 3.86538704e-06, 1.19155845e-06, 5.25066798e-06,\n",
       "        4.28499197e-06, 2.98150262e-05, 9.80225877e-07, 1.72064792e-05,\n",
       "        2.14208139e-05, 1.16722576e-05, 1.80304796e-05, 4.42402597e-05,\n",
       "        1.59433841e-06, 3.12483826e-05, 6.58932458e-06, 3.10730037e-08,\n",
       "        3.83124870e-06, 2.79261798e-07, 4.62848911e-05, 7.84059580e-07,\n",
       "        7.65383593e-05, 7.33706975e-06, 2.27068464e-04, 8.51639868e-07,\n",
       "        8.30294357e-06, 1.99457845e-05, 4.82948817e-05, 1.65295239e-06,\n",
       "        4.40117983e-05, 3.67676222e-07, 4.39260702e-06, 1.70465224e-04,\n",
       "        5.90608352e-07, 3.83927909e-05, 2.34051386e-05, 1.89024322e-05,\n",
       "        3.29228824e-05, 9.22772815e-05, 1.15486891e-05, 1.01969608e-05,\n",
       "        1.29738022e-04, 4.49292685e-07, 9.50350295e-05, 8.38632695e-06,\n",
       "        1.77449692e-05, 5.18945853e-07, 4.40755175e-05, 5.93427649e-06,\n",
       "        4.65245967e-06, 1.25792576e-04, 1.29438695e-06, 1.54466325e-05,\n",
       "        1.31763309e-05, 1.45565500e-05, 1.05946299e-07, 1.68450629e-06,\n",
       "        3.62634682e-06, 4.62547314e-06, 4.44097714e-05, 7.72383282e-05,\n",
       "        1.04780361e-06, 1.41932269e-05, 2.24126779e-06, 9.62450395e-06,\n",
       "        7.69941926e-06, 3.98799045e-07, 4.99903035e-06, 1.74535071e-05,\n",
       "        1.54484820e-04, 8.73435454e-07, 2.90433709e-05, 1.87699072e-04,\n",
       "        1.30256667e-05, 1.53892597e-05, 7.61327101e-07, 1.13954129e-05,\n",
       "        1.86023408e-06, 5.29931413e-06, 2.72020879e-05, 2.86634786e-05,\n",
       "        1.00134332e-06, 3.03713676e-07, 3.11873623e-06, 1.31045738e-07,\n",
       "        4.01168480e-04, 2.37852919e-06, 3.77536853e-05, 2.60756551e-05,\n",
       "        3.04017817e-06, 2.50836592e-06, 5.40065457e-06, 4.80730705e-07,\n",
       "        1.28498776e-08, 6.92479720e-04, 1.02675280e-04, 9.03088392e-07,\n",
       "        2.32820075e-05, 1.89153070e-05, 2.23026359e-06, 3.19615111e-07,\n",
       "        3.22582418e-05, 4.22922254e-04, 4.54842302e-06, 9.23909192e-06,\n",
       "        1.86162470e-05, 5.43334750e-07, 1.57121030e-05, 1.74925719e-06,\n",
       "        9.39040983e-05, 4.20234119e-06, 4.60264822e-08, 2.05346123e-06,\n",
       "        1.03399625e-05, 1.01284922e-06, 2.47227774e-07, 1.06022253e-06,\n",
       "        4.92602849e-05, 1.34331684e-04, 8.11988173e-07, 6.87691227e-06,\n",
       "        3.39350547e-04, 2.00389404e-05, 2.31778089e-04, 2.19599019e-06,\n",
       "        7.28536816e-06, 2.97727155e-07, 3.46613001e-06, 1.78362916e-06,\n",
       "        3.55966476e-04, 5.90154241e-06, 3.03698198e-06, 2.56774110e-05,\n",
       "        2.05394122e-06, 1.24812759e-05, 4.46368904e-05, 1.58050307e-06,\n",
       "        1.66751979e-05, 1.16089745e-06, 6.45447926e-06, 3.63650979e-05,\n",
       "        9.70736528e-06, 2.92830264e-05, 5.29041688e-04, 4.22621670e-05,\n",
       "        4.12667077e-07, 1.13607828e-04, 9.49086711e-07, 2.76747755e-06,\n",
       "        1.01515281e-04, 9.31247414e-05, 1.17388012e-07, 9.91797569e-05,\n",
       "        4.47886714e-06, 9.40477184e-06, 9.65490017e-07, 5.09199822e-07,\n",
       "        4.30251384e-06, 1.46153343e-05, 3.57263380e-05, 9.57711200e-06,\n",
       "        1.44496898e-05, 9.37187724e-06, 3.34285251e-05, 6.77996832e-06,\n",
       "        9.13365602e-06, 1.41527998e-05, 2.91301931e-05, 1.56463182e-04,\n",
       "        1.70598323e-05, 3.95598618e-05, 3.07752780e-05, 3.12159568e-06,\n",
       "        5.29539875e-06, 7.92700972e-04, 1.94285385e-05, 3.58284922e-07,\n",
       "        1.11765521e-05, 7.69744020e-07, 1.16111664e-06, 4.49918116e-06,\n",
       "        3.50437513e-05, 4.65590419e-04, 3.54110966e-06, 1.71059446e-06,\n",
       "        7.62606817e-07, 2.54220322e-05, 1.48632489e-06, 9.28678128e-05,\n",
       "        1.82514759e-05, 4.23814308e-05, 5.70370867e-05, 3.64320726e-06,\n",
       "        6.21679692e-06, 6.82040700e-05, 7.69856342e-07, 2.46659647e-06,\n",
       "        7.08107427e-06, 1.46511502e-06, 7.94156440e-05, 4.57200088e-07,\n",
       "        2.05631477e-06, 4.11264919e-05, 6.58270495e-04, 4.32884044e-05,\n",
       "        3.09591705e-05, 2.29591728e-06, 1.14148716e-05, 1.52998109e-06,\n",
       "        1.62256911e-05, 8.36426334e-05, 4.04527736e-06, 1.64561663e-06,\n",
       "        2.33572518e-06, 2.58952441e-05, 4.68461192e-04, 8.22664697e-06,\n",
       "        9.54775242e-05, 2.75704715e-05, 3.87763021e-06, 3.85509193e-05,\n",
       "        1.72740602e-06, 5.49060928e-07, 4.78637389e-07, 1.95149710e-06,\n",
       "        6.74383991e-05, 1.83697830e-05, 1.15126767e-03, 2.68894428e-06,\n",
       "        1.15421599e-05, 1.21118474e-05, 5.89435967e-06, 2.65185023e-04,\n",
       "        3.47705873e-06, 3.31198280e-05, 1.05337335e-06, 1.08001552e-06,\n",
       "        2.27661485e-06, 7.66631274e-07, 3.31516821e-05, 1.57797967e-05,\n",
       "        1.51798119e-07, 3.64652152e-07, 7.85246357e-07, 1.32872128e-05,\n",
       "        4.73565524e-06, 2.52139529e-07, 1.22277731e-06, 1.81041050e-05,\n",
       "        4.91264109e-06, 7.03658714e-07, 4.14212491e-06, 1.17235475e-04,\n",
       "        5.38214181e-07, 1.42335591e-06, 1.56745828e-05, 2.11134375e-06,\n",
       "        6.30637442e-06, 1.23513328e-05, 6.29039050e-06, 4.51956254e-07,\n",
       "        2.61703735e-05, 3.21974476e-05, 1.82143340e-05, 7.84715212e-06,\n",
       "        4.24220525e-06, 5.71179226e-05, 3.12318152e-05, 1.01556418e-06,\n",
       "        2.00570935e-06, 1.16100873e-05, 5.55002771e-06, 2.16751778e-03,\n",
       "        2.59240096e-05, 4.58859724e-08, 3.15827965e-05, 1.85691717e-03,\n",
       "        7.71310340e-08, 2.99203430e-06, 1.11092950e-05, 1.58735893e-05,\n",
       "        1.16371011e-05, 4.80784365e-05, 2.32442253e-05, 1.64587868e-06,\n",
       "        6.62514992e-07, 6.37894755e-06, 2.54005357e-07, 1.90176740e-06,\n",
       "        4.15220857e-05, 3.21940547e-06, 8.24106428e-06, 3.89051320e-06,\n",
       "        7.60597061e-07, 3.45903027e-06, 2.10473246e-07, 3.24807661e-06,\n",
       "        9.96345188e-04, 2.33380592e-06, 2.49317168e-06, 8.43400994e-06,\n",
       "        1.13572241e-05, 3.20593208e-05, 6.85634359e-06, 1.42957564e-04,\n",
       "        7.77836249e-07, 1.53080346e-05, 2.42073429e-06, 2.18894820e-06,\n",
       "        1.75046387e-06, 7.15990654e-06, 1.85674180e-05, 1.42391127e-06,\n",
       "        4.01827037e-06, 2.38613247e-05, 1.31650202e-04, 1.62951551e-06,\n",
       "        5.22556889e-04, 4.12509136e-04, 2.82811925e-05, 1.58192433e-05,\n",
       "        2.36198730e-06, 1.03596585e-06, 5.15902502e-06, 1.49552661e-05,\n",
       "        3.34751955e-03, 1.14458473e-03, 1.74022643e-05, 8.59930606e-06,\n",
       "        2.38327470e-06, 2.80809036e-06, 1.92043153e-05, 2.33884361e-06,\n",
       "        1.49012294e-06, 7.27878160e-07, 2.48350398e-06, 7.45234843e-08,\n",
       "        3.81352329e-05, 8.67981180e-06, 9.82618221e-05, 1.84886449e-05,\n",
       "        5.48297203e-06, 1.29297487e-05, 1.86671002e-06, 2.97613178e-06,\n",
       "        3.82783185e-07, 8.63564253e-07, 7.09499943e-08, 1.28736056e-05,\n",
       "        1.91700765e-05, 1.10600915e-04, 5.15057138e-07, 1.81097255e-06,\n",
       "        1.46246894e-05, 3.77460140e-07, 5.85700718e-06, 3.02756177e-07,\n",
       "        5.13116674e-07, 1.02526592e-05, 8.96272411e-07, 5.60772742e-06,\n",
       "        7.56109131e-08, 1.52001220e-07, 2.89047534e-06, 4.48834680e-06,\n",
       "        2.13422467e-07, 2.14633974e-06, 6.81215738e-07, 4.57204862e-07,\n",
       "        9.07738126e-07, 5.00577107e-06, 1.78276184e-06, 1.59942857e-07,\n",
       "        4.20258345e-07, 2.73922683e-06, 2.00783938e-06, 3.38347093e-08,\n",
       "        1.08518648e-07, 8.65790753e-07, 6.19072352e-06, 7.36637219e-07,\n",
       "        1.31416573e-05, 6.47413208e-06, 6.15110821e-07, 5.02297894e-07,\n",
       "        3.95028934e-07, 1.47052538e-06, 2.05637461e-05, 2.58369914e-06,\n",
       "        3.66946420e-04, 1.24842045e-05, 6.01832767e-07, 5.78132604e-05,\n",
       "        2.36889804e-07, 1.71708564e-07, 1.20225786e-05, 2.15130200e-07,\n",
       "        2.41202940e-07, 8.50885669e-07, 5.24106781e-06, 5.76018948e-08,\n",
       "        6.46524754e-08, 3.03907545e-05, 4.18632908e-06, 1.15869135e-07,\n",
       "        2.77956133e-07, 1.11209920e-06, 6.62710562e-08, 9.67046981e-06,\n",
       "        1.65750828e-06, 1.48717709e-06, 1.00174198e-07, 5.68221367e-07,\n",
       "        1.34684944e-06, 1.73558732e-07, 4.44270057e-07, 3.30138988e-07,\n",
       "        8.10485687e-07, 8.93071501e-08, 7.33930938e-06, 1.61836651e-04]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prédir la classe de l'image (parmi les 1000 classes d'ImageNet)\n",
    "y = vgg16.predict(img)  \n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4-fH2TjbDQIT"
   },
   "source": [
    "On obtient la sortie finale du réseau, c'est-à-dire une liste de 1000 probabilités."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cfFie5zzDQIU"
   },
   "source": [
    "### Décodage de la prédicition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aIDwCRSEDQIW"
   },
   "source": [
    "Les classes correspondant à ces probabilités ne sont pas explicitement données. La fonction  decode_predictions  de  keras.applications.vgg16  permet alors de récupérer cette information.  Ainsi, on peut faire un top 3 des classes les plus probables de l'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2bzD2bmqDQIX",
    "outputId": "a03ba8fa-89c7-4979-82e2-ec0262e77999"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 3 classes  are:  [('n02124075', 'Egyptian_cat', 0.8185691), ('n02441942', 'weasel', 0.05100181), ('n02123045', 'tabby', 0.024613801)]\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import decode_predictions\n",
    "\n",
    "#afficher les 3 classes les plus probables\n",
    "print('top 3 classes  are: ', decode_predictions(y, top=3)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qwb-rVbaDQIe"
   },
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CRij2MB9DQIh"
   },
   "source": [
    " Dans les trois cas, fine-tuning total, extraction des features, et fine-tuning partiel, il faut remplacer les dernières couches fully-connected qui permettent de classifier l'image dans une des 1000 classes ImageNet) par un classifieur plus adapté à notre problème.  Par exemple, supposons qu'on veuille différencier un chat d'un chien (classification binaire).\n",
    " \n",
    " La suppression des dernières couches se fait en ajoutant l'argument  include_top = False  lors de l'import du modèle pré-entraîné. Dans ce cas, il faut aussi préciser les dimensions des images en entrée (input_shape ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m51-FcswDQIi",
    "outputId": "f32d04ca-9b3d-4446-aa69-b429c51f3f26"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fatah\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# Charger VGG-16 pré-entraîné sur ImageNet et sans les couches fully-connected\n",
    "vgg16_2=VGG16(weights=\"imagenet\", include_top=False, input_shape=(224, 224,3))\n",
    "\n",
    "#récuperer la sortie de ce réseau\n",
    "x=vgg16_2.output\n",
    "\n",
    "# Ajouter la nouvelle couche fully-connected pour la classification à 10 classes\n",
    "predictions= Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Définir le nouveau modèle\n",
    "new_model=Model(inputs=vgg16_2.input, output=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "znBlX5wKDQIn",
    "outputId": "9fa8275f-f6a9-4e50-dfcc-166e32bbfa51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 7, 7, 10)          5130      \n",
      "=================================================================\n",
      "Total params: 14,719,818\n",
      "Trainable params: 5,130\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(new_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QLTmPwhWDQIr"
   },
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "plot_model(new_model,to_file='new_model.png')\n",
    "\n",
    "#Pourquoi ça ne marche pas??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R8_A2sYJDQIu"
   },
   "source": [
    "### Stratégie #1 : fine-tuning total\n",
    "Ici, on entraîne tout le réseau, donc il faut rendre toutes les couches \"entraînables\" :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1LoyoXdQDQIu"
   },
   "outputs": [],
   "source": [
    "for layer in vgg16_2.layers:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5dVGPPPkDQIy"
   },
   "source": [
    "### Stratégie #2 : extraction de features\n",
    "On entraîne seulement le nouveau classifieur et on ne ré-entraîne pas les autres couches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-xBKKHNvDQIz"
   },
   "outputs": [],
   "source": [
    "for layer in vgg16_2.layers:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "52qbeK2QDQI3"
   },
   "source": [
    "### Stratégie #3 : fine-tuning partiel\n",
    "On entraîne le nouveau classifieur et les couches hautes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CDDPUabaDQI5"
   },
   "outputs": [],
   "source": [
    "for layer in vgg16_2.layers[:5]:\n",
    "    layer.trainable=False\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zexV5js9DQI8"
   },
   "source": [
    "### Entraînement du réseau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LRjIGkcTDQI9"
   },
   "outputs": [],
   "source": [
    "#charger une image\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "#charger l'image\n",
    "img2=load_img('C:\\\\Users\\Fatah\\Downloads\\Stage\\Pratique\\chat.jpg',target_size=(224,224)) \n",
    "\n",
    "# Convertir en tableau numpy\n",
    "img2= img_to_array(img2)\n",
    "\n",
    "# Créer la collection d'images (un seul échantillon)\n",
    "img2=img.reshape((1,img2.shape[0],img2.shape[1],img2.shape[2]))\n",
    "\n",
    "# Prétraiter l'image comme le veut VGG-16\n",
    "img2=preprocess_input(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "168LLFVDDQI_"
   },
   "outputs": [],
   "source": [
    "# Compiler le modèle \n",
    "new_model.compile(loss='categorical_crossentropy',optimizer=optimizers.SGD(lr=0.0001, momentum=0.9),metrics=['accuracy'])\n",
    "\n",
    "# Entraîner sur les données d'entraînement (X_train, y_train)\n",
    "#new_model.fit()\n",
    "#faut tester et trouver un tuto pour apprendre ça"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_gnrGuXrDQJD"
   },
   "source": [
    "### suite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e5HLWgOtDQJE"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Oj1XdcVG3Kq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xdJT4ZqDGHAN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "HDFbILS3DQHH",
    "efGaf2OgDQHT",
    "XghJ8WNDDQHa",
    "u4-g0kOBDQHr",
    "QrcsuLfIDQH4",
    "IEosCAXLDQIB",
    "nc6uBMAjDQIK",
    "7ZCs5XdSDQIO",
    "cfFie5zzDQIU",
    "R8_A2sYJDQIu",
    "5dVGPPPkDQIy",
    "52qbeK2QDQI3",
    "zexV5js9DQI8"
   ],
   "name": "Apprendre.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
